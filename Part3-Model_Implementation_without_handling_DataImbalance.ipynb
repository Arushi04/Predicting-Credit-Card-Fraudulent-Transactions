{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"processed_train.csv\")\n",
    "X_test = pd.read_csv(\"processed_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping additional column\n",
    "\n",
    "X_sm = X_train.drop('Unnamed: 0', axis=1)\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "y_sm = y_train.drop('Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop('Unnamed: 0', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "def print_eval(y_pred, model):\n",
    "    print(\"Training Accuracy: \", model.score(X_sm, y_sm))\n",
    "    print(\"Testing Accuracy: \", model.score(X_test, y_test))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print('Precision: %.3f' % precision)\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print('Recall: %.3f' % recall)\n",
    "    \n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print('F-Measure: %.3f' % score)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation:\n",
    "\n",
    ">1\tLogistic Regression   \n",
    "2\tSVM    \n",
    "3\tRandom Forest   \n",
    "4\tDecision Tree  \n",
    "5   Gradient Boosting\n",
    "6\tArtificial Neural Network   \n",
    "7   Penalized-SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9940231977049079\n",
      "Testing Accuracy:  0.9947095659684734\n",
      "[[27639    17]\n",
      " [  130     0]]\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.50      0.50      0.50     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : Logistic Regression\n",
    "\n",
    "model_lr = LogisticRegression(random_state=42)\n",
    "model_lr.fit(X_sm, y_sm)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_lr, model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 SVM with linear kernel and c=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f756053e7d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training and predictions : SVM\n",
    "\n",
    "model_svm = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42)),\n",
    "    ])\n",
    "\n",
    "model_svm.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "print_eval(y_pred_svm, model_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 SVM with linear kernel and c=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9784063917080544\n",
      "Testing Accuracy:  0.9815374649103865\n",
      "[[27254   402]\n",
      " [  111    19]]\n",
      "Precision: 0.045\n",
      "Recall: 0.146\n",
      "F-Measure: 0.069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     27656\n",
      "           1       0.05      0.15      0.07       130\n",
      "\n",
      "    accuracy                           0.98     27786\n",
      "   macro avg       0.52      0.57      0.53     27786\n",
      "weighted avg       0.99      0.98      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm1 = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=50, loss=\"hinge\", random_state=42)),\n",
    "    ])\n",
    "\n",
    "model_svm1.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_svm1 = model_svm1.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_svm1, model_svm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 SVM with linear kernel, c=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9899281241323996\n",
      "Testing Accuracy:  0.9916144821132945\n",
      "[[27540   116]\n",
      " [  117    13]]\n",
      "Precision: 0.101\n",
      "Recall: 0.100\n",
      "F-Measure: 0.100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.10      0.10      0.10       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.55      0.55      0.55     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm2 = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=0.001, loss=\"hinge\", random_state=42)),\n",
    "    ])\n",
    "\n",
    "model_svm2.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_svm2 = model_svm2.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_svm2, model_svm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 SVM with polynomial kernel, degree=2,  c=1 and coef=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9959203504334145\n",
      "Testing Accuracy:  0.9937378535953357\n",
      "[[27611    45]\n",
      " [  129     1]]\n",
      "Precision: 0.022\n",
      "Recall: 0.008\n",
      "F-Measure: 0.011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.02      0.01      0.01       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.51      0.50      0.50     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm_poly = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=2, coef0=1, C=1))\n",
    "    ])\n",
    "\n",
    "model_svm_poly.fit(X_sm, y_sm)\n",
    "y_pred_svm_poly = model_svm_poly.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_svm_poly, model_svm_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 SVM with polynomial kernel, degree=3, c=5, coef=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_poly1 = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "    ])\n",
    "\n",
    "model_svm_poly1.fit(X_sm, y_sm)\n",
    "y_pred_svm_poly1 = model_svm_poly1.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_svm_poly1, model_svm_poly1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 SVM with RBF kernel, c=0.001 and gamma=5 (running for hours with no result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_rbf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "    ])\n",
    "\n",
    "model_svm_rbf.fit(X_sm, y_sm)\n",
    "y_pred_svm_rbf = model_svm_rbf.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_svm_rbf, model_svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Random Forest with n_estimators=100, max_leaf_nodes=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9821235771354536\n",
      "Testing Accuracy:  0.9884834089109623\n",
      "[[27386   270]\n",
      " [   50    80]]\n",
      "Precision: 0.229\n",
      "Recall: 0.615\n",
      "F-Measure: 0.333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     27656\n",
      "           1       0.23      0.62      0.33       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.61      0.80      0.66     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : random forest\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, random_state=42)\n",
    "model_rf.fit(X_sm, y_sm)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf, model_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Random Forest with n_estimators=150, max_leaf_nodes=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9818305210229201\n",
      "Testing Accuracy:  0.988267472828043\n",
      "[[27381   275]\n",
      " [   51    79]]\n",
      "Precision: 0.223\n",
      "Recall: 0.608\n",
      "F-Measure: 0.326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     27656\n",
      "           1       0.22      0.61      0.33       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.61      0.80      0.66     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : random forest\n",
    "\n",
    "model_rf1 = RandomForestClassifier(n_estimators=150, max_leaf_nodes=16, random_state=42)\n",
    "model_rf1.fit(X_sm, y_sm)\n",
    "y_pred_rf1 = model_rf1.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf1, model_rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Random Forest with n_estimators=100, max_leaf_nodes=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9866659468797236\n",
      "Testing Accuracy:  0.9903908443100842\n",
      "[[27443   213]\n",
      " [   54    76]]\n",
      "Precision: 0.263\n",
      "Recall: 0.585\n",
      "F-Measure: 0.363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     27656\n",
      "           1       0.26      0.58      0.36       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.63      0.79      0.68     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : random forest\n",
    "\n",
    "model_rf2 = RandomForestClassifier(n_estimators=100, max_leaf_nodes=32, random_state=42)\n",
    "model_rf2.fit(X_sm, y_sm)\n",
    "y_pred_rf2 = model_rf2.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf2, model_rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Decision tree with full max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.9925502051392787\n",
      "[[27530   126]\n",
      " [   81    49]]\n",
      "Precision: 0.280\n",
      "Recall: 0.377\n",
      "F-Measure: 0.321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.28      0.38      0.32       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.64      0.69      0.66     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : decision tree\n",
    "\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_dt.fit(X_sm, y_sm)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_dt, model_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Decision tree with max_depth=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.980396088472098\n",
      "Testing Accuracy:  0.9789102425681998\n",
      "[[27101   555]\n",
      " [   31    99]]\n",
      "Precision: 0.151\n",
      "Recall: 0.762\n",
      "F-Measure: 0.253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     27656\n",
      "           1       0.15      0.76      0.25       130\n",
      "\n",
      "    accuracy                           0.98     27786\n",
      "   macro avg       0.58      0.87      0.62     27786\n",
      "weighted avg       0.99      0.98      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : decision tree\n",
    "\n",
    "model_dt1 = DecisionTreeClassifier(max_depth=16, random_state=42)\n",
    "model_dt1.fit(X_sm, y_sm)\n",
    "y_pred_dt1 = model_dt1.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_dt1, model_dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.983658265724774\n",
      "Testing Accuracy:  0.9885553876052688\n",
      "[[27376   280]\n",
      " [   38    92]]\n",
      "Precision: 0.247\n",
      "Recall: 0.708\n",
      "F-Measure: 0.367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     27656\n",
      "           1       0.25      0.71      0.37       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.62      0.85      0.68     27786\n",
      "weighted avg       1.00      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier(random_state=0)\n",
    "model_gb.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_gb, model_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Observations with handling Imbalance : Class 1(Fraud)\n",
    "\n",
    "|                                       | Precision     |   Recall      |    f1-score    | \n",
    "|---------------------------------------|---------------|---------------|----------------|\n",
    "|Logistic Regression                    |     0.00      |     0.00      |     0.00       | \n",
    "|SVM (Linear, c=1)                      |     0.10      |     0.14      |     0.12       | \n",
    "|SVM (Linear, c=50)                     |     0.05      |     0.15      |     0.07       | \n",
    "|SVM (Linear, c=0.001)                  |     0.10      |     0.10      |     0.10       | \n",
    "|SVM (Poly, c=1, degree=2)              |     0.02      |     0.01      |     0.01       |\n",
    "|SVM (Poly, c=5, degree=3)              |     0.159     |     0.085     |     0.111      |\n",
    "|SVM (RBF, c=.001, gamma=5)             |               |               |                |\n",
    "|Random Forest (n_est=100, max_node=16) |     0.23      |     0.62      |     0.33       | \n",
    "|Random Forest (n_est=100, max_node=32) |     0.26      |     0.58      |     0.36       | \n",
    "|Random Forest (n_est=150, max_node=16) |     0.22      |     0.61      |     0.33       |\n",
    "|Decision Tree (max_depth)              |     0.28      |     0.38      |     0.32       | \n",
    "|Decision Tree (max_depth=16)           |     0.15      |     0.76      |     0.25       |\n",
    "|Gradient Boost                         |     0.25      |     0.71      |     0.37       |  \n",
    "|ANN                                    |     0.11      |     0.05      |     0.07       |  \n",
    "|Penalized SVM                          |     0.96      |     0.78      |     0.98       |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.022696424715427092\n",
      "Testing Accuracy:  0.022025480457784494\n",
      "[[27609    47]\n",
      " [  124     6]]\n",
      "Precision: 0.113\n",
      "Recall: 0.046\n",
      "F-Measure: 0.066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.11      0.05      0.07       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.55      0.52      0.53     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_sm)\n",
    "X_trans = scaler.transform(X_sm)\n",
    "X_trans_test = scaler.transform(X_test)\n",
    "\n",
    "# Applying model\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "model_mlp.fit(X_trans, y_sm.values.ravel())\n",
    "\n",
    "y_pred_mlp = model_mlp.predict(X_trans_test)\n",
    "print_eval(y_pred_mlp, model_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
