{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"processed_train.csv\")\n",
    "X_test = pd.read_csv(\"processed_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping extra columns form the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fraud\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.drop('Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop('Unnamed: 0', axis=1)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>age</th>\n",
       "      <th>food_dining</th>\n",
       "      <th>gas_transport</th>\n",
       "      <th>grocery_net</th>\n",
       "      <th>...</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>6-12</th>\n",
       "      <th>12-18</th>\n",
       "      <th>18-24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.00</td>\n",
       "      <td>47.1709</td>\n",
       "      <td>-100.7944</td>\n",
       "      <td>1190</td>\n",
       "      <td>46.398331</td>\n",
       "      <td>-99.813959</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284.88</td>\n",
       "      <td>46.5901</td>\n",
       "      <td>-117.1692</td>\n",
       "      <td>761</td>\n",
       "      <td>45.687331</td>\n",
       "      <td>-117.488135</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.07</td>\n",
       "      <td>27.9551</td>\n",
       "      <td>-82.2966</td>\n",
       "      <td>79613</td>\n",
       "      <td>27.254081</td>\n",
       "      <td>-81.974799</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.38</td>\n",
       "      <td>34.0770</td>\n",
       "      <td>-84.3033</td>\n",
       "      <td>165556</td>\n",
       "      <td>34.551957</td>\n",
       "      <td>-83.374265</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.52</td>\n",
       "      <td>43.6088</td>\n",
       "      <td>-83.9530</td>\n",
       "      <td>67858</td>\n",
       "      <td>43.032957</td>\n",
       "      <td>-83.521294</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 571 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amt      lat      long  city_pop  merch_lat  merch_long  age  \\\n",
       "0   20.00  47.1709 -100.7944      1190  46.398331  -99.813959   70   \n",
       "1  284.88  46.5901 -117.1692       761  45.687331 -117.488135   75   \n",
       "2    5.07  27.9551  -82.2966     79613  27.254081  -81.974799   41   \n",
       "3   45.38  34.0770  -84.3033    165556  34.551957  -83.374265   21   \n",
       "4   27.52  43.6088  -83.9530     67858  43.032957  -83.521294   24   \n",
       "\n",
       "   food_dining  gas_transport  grocery_net  ...  06  07  08  09  10  11  12  \\\n",
       "0            0              0            1  ...   0   0   0   0   0   0   0   \n",
       "1            0              0            0  ...   0   0   0   0   0   0   0   \n",
       "2            0              0            0  ...   0   0   0   0   0   0   0   \n",
       "3            1              0            0  ...   0   0   0   1   0   0   0   \n",
       "4            0              0            0  ...   0   0   1   0   0   0   0   \n",
       "\n",
       "   6-12  12-18  18-24  \n",
       "0     1      0      0  \n",
       "1     0      0      1  \n",
       "2     0      0      1  \n",
       "3     0      1      0  \n",
       "4     0      0      1  \n",
       "\n",
       "[5 rows x 571 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop('Unnamed: 0', axis=1)\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Baseline Model before Balancing the data using Sampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model_lr = LogisticRegression(random_state=42)\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation 1. Logistic Regression\n",
    "\n",
    "def print_eval(y_pred, model):\n",
    "    print(\"Training Accuracy: \", model.score(X_train, y_train))\n",
    "    print(\"Testing Accuracy: \", model.score(X_test, y_test))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print('Precision: %.3f' % precision)\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print('Recall: %.3f' % recall)\n",
    "    \n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print('F-Measure: %.3f' % score)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9940231977049079\n",
      "Testing Accuracy:  0.9947095659684734\n",
      "[[27639    17]\n",
      " [  130     0]]\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.50      0.50      0.50     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval(y_pred_lr, model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9945630379122066\n",
      "Testing Accuracy:  0.9953213848700785\n",
      "[[27656     0]\n",
      " [  130     0]]\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F-Measure: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           1.00     27786\n",
      "   macro avg       0.50      0.50      0.50     27786\n",
      "weighted avg       0.99      1.00      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation 2. Random Forest\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf, model_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.9966529907147484\n",
      "[[27610    46]\n",
      " [   47    83]]\n",
      "Precision: 0.643\n",
      "Recall: 0.638\n",
      "F-Measure: 0.641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.64      0.64      0.64       130\n",
      "\n",
      "    accuracy                           1.00     27786\n",
      "   macro avg       0.82      0.82      0.82     27786\n",
      "weighted avg       1.00      1.00      1.00     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation 3. Decision tree\n",
    "\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_dt, model_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to handling the Imbalance in data \n",
    "\n",
    "   \n",
    "Handling the Imbalance in data by one of the following methods:   \n",
    "> 4.1 Random Under-Sampling   \n",
    "       4.2 Random Over-Sampling   \n",
    "       4.3 SMOTE (Synthetic Minority over sampling technique)   \n",
    "       4.4 Near Miss algorighm ( under sampling )   \n",
    "       4.5 Ensemble method \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating X_train and y_train before doing sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129668, 1) (129668, 571)\n",
      "shape of train set :  (129668, 572)\n",
      "128963 705\n",
      "Non fraud cases :  (128963, 572) Fraud cases :  (705, 572)\n"
     ]
    }
   ],
   "source": [
    "# Adding the dependent feature in the train data set\n",
    "\n",
    "print(y_train.shape, X_train.shape)\n",
    "df_train = pd.concat([X_train, y_train], axis = 1)\n",
    "print(\"shape of train set : \", df_train.shape)\n",
    "\n",
    "# Class count\n",
    "count_class_0, count_class_1 = df_train.is_fraud.value_counts()\n",
    "print(count_class_0, count_class_1)\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df_train[df_train['is_fraud'] == 0]\n",
    "df_class_1 = df_train[df_train['is_fraud'] == 1]\n",
    "print(\"Non fraud cases : \", df_class_0.shape, \"Fraud cases : \", df_class_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling : \n",
    "We randomly drop the samples from the majority class(class 0) to balance both the classes 0(normal) and 1(fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "1    705\n",
      "0    705\n",
      "Name: is_fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_train_undersample = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_train_undersample.is_fraud.value_counts())\n",
    "\n",
    "X = df_train_undersample.drop('is_fraud', axis='columns')\n",
    "y = df_train_undersample['is_fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic regression after under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9464401394330135\n",
      "Testing Accuracy:  0.9474915425034189\n",
      "[[26227  1429]\n",
      " [   30   100]]\n",
      "Precision: 0.065\n",
      "Recall: 0.769\n",
      "F-Measure: 0.121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     27656\n",
      "           1       0.07      0.77      0.12       130\n",
      "\n",
      "    accuracy                           0.95     27786\n",
      "   macro avg       0.53      0.86      0.55     27786\n",
      "weighted avg       0.99      0.95      0.97     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : Logistic Regression\n",
    "\n",
    "model_lr_undersample = LogisticRegression(random_state=42)\n",
    "model_lr_undersample.fit(X, y)\n",
    "y_pred_lr_us = model_lr_undersample.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_lr_us, model_lr_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest after under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9572600795878705\n",
      "Testing Accuracy:  0.9589361548981501\n",
      "[[26545  1111]\n",
      " [   30   100]]\n",
      "Precision: 0.083\n",
      "Recall: 0.769\n",
      "F-Measure: 0.149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27656\n",
      "           1       0.08      0.77      0.15       130\n",
      "\n",
      "    accuracy                           0.96     27786\n",
      "   macro avg       0.54      0.86      0.56     27786\n",
      "weighted avg       0.99      0.96      0.98     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : random forest\n",
    "\n",
    "model_rf_undersample = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, random_state=42)\n",
    "model_rf_undersample.fit(X, y)\n",
    "y_pred_rf_us = model_rf_undersample.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf_us, model_rf_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree after under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9261498596415461\n",
      "Testing Accuracy:  0.9271935507089901\n",
      "[[25635  2021]\n",
      " [    2   128]]\n",
      "Precision: 0.060\n",
      "Recall: 0.985\n",
      "F-Measure: 0.112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     27656\n",
      "           1       0.06      0.98      0.11       130\n",
      "\n",
      "    accuracy                           0.93     27786\n",
      "   macro avg       0.53      0.96      0.54     27786\n",
      "weighted avg       1.00      0.93      0.96     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : decision tree\n",
    "\n",
    "model_dt_undersample = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_undersample.fit(X,y)\n",
    "y_pred_dt_us = model_dt_undersample.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_dt_us, model_dt_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision of results and Observations :\n",
    "\n",
    "|                                       | Precision|    |     Recall    | f1-score       |\n",
    "|---------------------------------------|---------------|---------------|----------------|\n",
    "|Logistic Regression                    |     1.00      |     0.00      |     1.00       |\n",
    "|Decision Tree Classifier               |     1.00      |     0.64      |     1.00       |  \n",
    "|Random Forest Classifier               |     1.00      |     0.00      |     1.00       | \n",
    "|Logistic Regression Under Sampling     |     0.96      |     0.77      |     0.98       |\n",
    "|Decision Tree Classifier Under Sampling|     0.93      |     0.95      |     0.96       | \n",
    "|Random Forest Classifier Under Sampling|     0.96      |     0.78      |     0.98       |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Over Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over Sampling:\n",
    "We randomly replicate the samples from minority class (class 1) to balance it with the majority class. It outperforms under sampling because there is no data loss but overfitting can be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    128963\n",
      "0    128963\n",
      "Name: is_fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat the DataFrames of both class\n",
    "\n",
    "df_class_1_over = df_class_1.sample(count_class_0,replace=True)\n",
    "df_train_oversample = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_train_oversample.is_fraud.value_counts())\n",
    "\n",
    "X = df_train_oversample.drop('is_fraud', axis='columns')\n",
    "y = df_train_oversample['is_fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression after Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9493167165376192\n",
      "Testing Accuracy:  0.9510184985244368\n",
      "[[26325  1331]\n",
      " [   30   100]]\n",
      "Precision: 0.070\n",
      "Recall: 0.769\n",
      "F-Measure: 0.128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     27656\n",
      "           1       0.07      0.77      0.13       130\n",
      "\n",
      "    accuracy                           0.95     27786\n",
      "   macro avg       0.53      0.86      0.55     27786\n",
      "weighted avg       0.99      0.95      0.97     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : Logistic Regression\n",
    "\n",
    "model_lr_oversample = LogisticRegression(random_state=42)\n",
    "model_lr_oversample.fit(X, y)\n",
    "y_pred_lr_os = model_lr_oversample.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_lr_os, model_lr_oversample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest after Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.966051762963877\n",
      "Testing Accuracy:  0.9667458432304038\n",
      "[[26765   891]\n",
      " [   33    97]]\n",
      "Precision: 0.098\n",
      "Recall: 0.746\n",
      "F-Measure: 0.174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     27656\n",
      "           1       0.10      0.75      0.17       130\n",
      "\n",
      "    accuracy                           0.97     27786\n",
      "   macro avg       0.55      0.86      0.58     27786\n",
      "weighted avg       0.99      0.97      0.98     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : random forest\n",
    "\n",
    "model_rf_oversample = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, random_state=42)\n",
    "model_rf_oversample.fit(X, y)\n",
    "y_pred_rf_os = model_rf_oversample.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf_os, model_rf_oversample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree after Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.9961491398546031\n",
      "[[27594    62]\n",
      " [   45    85]]\n",
      "Precision: 0.578\n",
      "Recall: 0.654\n",
      "F-Measure: 0.614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27656\n",
      "           1       0.58      0.65      0.61       130\n",
      "\n",
      "    accuracy                           1.00     27786\n",
      "   macro avg       0.79      0.83      0.81     27786\n",
      "weighted avg       1.00      1.00      1.00     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : decision tree\n",
    "\n",
    "model_dt_oversample = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_oversample.fit(X,y)\n",
    "y_pred_dt_os = model_dt_oversample.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_dt_os, model_dt_oversample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision of results and Observations :\n",
    "\n",
    "|                                       | Class-0 Recall| Class-1 Recall|Class-0 f1-score| Class-1 f1-score|\n",
    "|---------------------------------------|---------------|---------------|----------------|-----------------|\n",
    "|Logistic Regression                    |     1.00      |     0.00      |     1.00       |      0.00       |\n",
    "|Decision Tree Classifier               |     1.00      |     0.64      |     1.00       |      0.64       |\n",
    "|Random Forest Classifier               |     1.00      |     0.00      |     1.00       |      0.00       |\n",
    "|Logistic Regression Under Sampling     |     0.96      |     0.77      |     0.98       |      0.14       |\n",
    "|Decision Tree Classifier Under Sampling|     0.93      |     0.95      |     0.96       |      0.11       |\n",
    "|Random Forest Classifier Under Sampling|     0.96      |     0.78      |     0.98       |      0.15       |\n",
    "|Logistic Regression Over Sampling      |     0.95      |     0.77      |     0.97       |      0.13       |\n",
    "|Decision Tree Classifier Over Sampling |     1.00      |     0.68      |     1.00       |      0.64       |\n",
    "|Random Forest Classifier Over Sampling |     0.96      |     0.75      |     0.98       |      0.13       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SMOTE (Synthetic Minority Over Sampling Technique) - Informed Over Sampling\n",
    "\n",
    "- Choose minority class as the input vector\n",
    "- Find its k nearest neighbors (k_neighbors is specified as an argument in the SMOTE() function)\n",
    "- Choose one of these neighbors and place a synthetic point anywhere on the line joining the point under consideration and its chosen neighbor\n",
    "- Repeat the steps until data is balanced\n",
    "\n",
    "SMOTE mitigates the problem of overfitting caused by random oversampling as synthetic examples are generated rather than replicating the existing samples. It's not very effective for high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "1           128963\n",
       "0           128963\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smote implementation\n",
    "smote = SMOTE(sampling_strategy = 'minority')\n",
    "X_sm, y_sm = smote.fit_sample(X_train, y_train)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression after SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.949239596508005\n",
      "Testing Accuracy:  0.9505866263585978\n",
      "[[26313  1343]\n",
      " [   30   100]]\n",
      "Precision: 0.069\n",
      "Recall: 0.769\n",
      "F-Measure: 0.127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     27656\n",
      "           1       0.07      0.77      0.13       130\n",
      "\n",
      "    accuracy                           0.95     27786\n",
      "   macro avg       0.53      0.86      0.55     27786\n",
      "weighted avg       0.99      0.95      0.97     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : Logistic Regression\n",
    "\n",
    "model_lr_smote = LogisticRegression(random_state=42)\n",
    "model_lr_smote.fit(X_sm, y_sm)\n",
    "y_pred_lr_sm = model_lr_smote.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_lr_sm, model_lr_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest after SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9823549372242959\n",
      "Testing Accuracy:  0.9871518030662924\n",
      "[[27342   314]\n",
      " [   43    87]]\n",
      "Precision: 0.217\n",
      "Recall: 0.669\n",
      "F-Measure: 0.328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     27656\n",
      "           1       0.22      0.67      0.33       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.61      0.83      0.66     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : random forest\n",
    "\n",
    "model_rf_smote = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, random_state=42)\n",
    "model_rf_smote.fit(X_sm, y_sm)\n",
    "y_pred_rf_sm = model_rf_smote.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_rf_sm, model_rf_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision Tree after SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.9916144821132945\n",
      "[[27502   154]\n",
      " [   79    51]]\n",
      "Precision: 0.249\n",
      "Recall: 0.392\n",
      "F-Measure: 0.304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     27656\n",
      "           1       0.25      0.39      0.30       130\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.62      0.69      0.65     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and predictions : decision tree\n",
    "\n",
    "model_dt_smote = DecisionTreeClassifier(random_state=42)\n",
    "model_dt_smote.fit(X_sm,y_sm)\n",
    "y_pred_dt_sm = model_dt_smote.predict(X_test)\n",
    "\n",
    "print_eval(y_pred_dt_sm, model_dt_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision of results and Observations :\n",
    "\n",
    "|                                       | Class-0 Recall| Class-1 Recall|Class-0 f1-score| Class-1 f1-score|\n",
    "|---------------------------------------|---------------|---------------|----------------|-----------------|\n",
    "|Logistic Regression                    |     1.00      |     0.00      |     1.00       |      0.00       |\n",
    "|Decision Tree Classifier               |     1.00      |     0.64      |     1.00       |      0.64       |\n",
    "|Random Forest Classifier               |     1.00      |     0.00      |     1.00       |      0.00       |\n",
    "|Logistic Regression Under Sampling     |     0.96      |     0.77      |     0.98       |      0.14       |\n",
    "|Decision Tree Classifier Under Sampling|     0.93      |     0.95      |     0.96       |      0.11       |\n",
    "|Random Forest Classifier Under Sampling|     0.96      |     0.78      |     0.98       |      0.15       |\n",
    "|Logistic Regression Over Sampling      |     0.95      |     0.77      |     0.97       |      0.13       |\n",
    "|Decision Tree Classifier Over Sampling |     1.00      |     0.68      |     1.00       |      0.64       |\n",
    "|Random Forest Classifier Over Sampling |     0.96      |     0.75      |     0.98       |      0.13       |\n",
    "|Logistic Regression SMOTE              |     0.95      |     0.77      |     0.97       |      0.13       |\n",
    "|Decision Tree Classifier SMOTE         |     0.99      |     0.39      |     1.00       |      0.31       |\n",
    "|Random Forest Classifier SMOTE         |     0.99      |     0.66      |     0.99       |      0.33       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
